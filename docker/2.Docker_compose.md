DOCKER COMPOSE: work with multiple local containers




# Docker compose

## Introduction

`docker-compose` is a separate tool to:
* **start up multiple** Docker **containers** at the same time
* **Automate** containers' creation process
* **Allow network communications** between the containers.
  * All containers will created by _docker compose_ will be in the **same network** and they're going to have **free access to communicate to each other** in any way they want. 
  * You can access a container by its _service_ name
  * You just need to specify the **port mapping for external input ports** only (to receive incoming requests).

Docker compose relies on `docker-compose.yml` file.

!["introduction to Docker compose"](images/24_docker_compose_introduction.png "introduction to Docker compose")


Usage:
* `docker-compose up` to RUN the containers
* `docker-compose up --build` to BUILD then RUN the containers

!["docker compose usage"](images/25_docker_compose_commands.png "docker compose usage")


## Structure of docker-compose.yml 

* **Version**: there are different versions of the _docker-compose_ file syntax. During this training I am using `version: '3'`
* **Services**: a service is a _type of container_. Each service is usally a different Docker container.



# Docker-compose in action: create an application with multiples containers

:information_source: This is the _section 5_ exercice from the Udemy training

## Objectives

Create a NodeJS application that will count the number of times a web-page has been visited accross multiple instances.
* `multi containers` application
* NodeJS web-service
  * Expose a web-service that will return a String (~ like hello-world) on HTTP GET `/`
  * Do a `server-side console log` at each web-service call
  * `Listen` for incoming queries on `port 8080`
  * Increment the visit counter at each call
* Redis server
  * Save the visit counter

The solution must be able to scale-up!

!["section 5 objectives"](images/20_objectives_section_5.png "section 5 objectives")


## Architecture option 1: single container

If you package the application along the data repository, _inside_ the same container, you might end-up in such a situation: 

!["section 5 single container issue"](images/21_single_container_issues.png "section 5 single container issue")

Assuming there are many instances behind a load-balancer, and because **data repository is not unique and shared**: data becomes inconsistent over time!! 

:fire: This is NOT a correct architecture!!

> For a **correct architecture: 1 container == 1 purpose** && isolate data repository in dedicated container


## Architecture option 2: multiple containers

To scale easier, it is better to:
* separate concerns: **1 container for 1 purpose**. 
* **Isolate data repositories** and datasources
* Only duplicate application's logic and treatment. Not the data!

!["section 5 target architecture"](images/22_multiple_containes_architecture.png "section 5 target architecture")

:white_check_mark: With this kind of architecture you can easily scale up without data inconsistency or data loss.


## Implementation option 1: Dockerfile + separate REDIS container

We could try to: 
* _manually_ start a REDIS container 
* In parallel, build a new image for our application with a `Dockerfile`

!["network flow isolated containers"](images/23_network_flows_isolated_containers.png "network flow isolated containers")


> This option requires a **lot of manual operations** !!! It is very error-prone, fastidious and full of network issues

:fire::fire: too hard to demonstrate, and not convenient at all :fire::fire:


## Implementation option 2: docker-compose

The best approach, by far, is to use _docker compose_. You'll find an example of the [`docker-compose.yml`](./exercices/section_5/docker-compose.yml) file in exercices/section_5/

* Create `docker-compose.yml` file
* Run `docker-compose up --build` to build the image and start all containers
* Open `http://localhost:5000` in a browser to view the application (it redirects to NodeJS app port _8081_)



# Rules to follow to use multiple containers

When you have to work with multiple containers, you shall:
* Ensure your **applications are stateless with loose coupling**: they can run on many instances without issues
* **Separate containers** !!! 1 container == 1 purpose only
* Use **docker-compose**



# Resources

* [Docker compose v3 official documentation](https://docs.docker.com/compose/compose-file/compose-file-v3/)
* [Google cloud best practices with Docker](https://cloud.google.com/architecture/best-practices-for-building-containers#build-the-smallest-image-possible)


